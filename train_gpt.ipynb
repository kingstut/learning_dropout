{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from nanogpt import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "batch_size = 64\n",
    "block_size = 64\n",
    "\n",
    "#load data\n",
    "train_data = np.memmap('../data/shakespeare_char/train.bin', dtype=np.uint16, mode='r')\n",
    "val_data = np.memmap('../data/shakespeare_char/val.bin', dtype=np.uint16, mode='r')\n",
    "\n",
    "g = torch.Generator().manual_seed(214748364)\n",
    "\n",
    "def get_batch(type=\"train\"):\n",
    "    if type==\"train\":\n",
    "        data = train_data \n",
    "    elif type==\"val\":\n",
    "        data = val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,), generator=g)\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.21M\n",
      "num decayed parameter tensors: 6, with 213,120 parameters\n",
      "num non-decayed parameter tensors: 3, with 384 parameters\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-1\n",
    "beta2 = 0# 0.99 \n",
    "beta1 = 0 #0.9\n",
    "weight_decay = 0 #1e-1\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 64\n",
    "    vocab_size: int = 65\n",
    "    n_layer: int = 1\n",
    "    n_head: int = 4\n",
    "    n_embd: int = 128\n",
    "    bias: bool = False\n",
    "    \n",
    "gptconf = GPTConfig()\n",
    "model = GPT(gptconf)\n",
    "optimizer = model.configure_optimizers(weight_decay, lr, (beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = 0.9\n",
    "p1 = 1.0\n",
    "dropout_dict = {'transformer.wte.weight':p0,\n",
    "                'transformer.wpe.weight':p0, \n",
    "                'transformer.h.0.ln_1.weight':p1, \n",
    "                'transformer.h.0.attn.c_attn.weight':p0, \n",
    "                'transformer.h.0.attn.c_proj.weight':p0, \n",
    "                'transformer.h.0.ln_2.weight':p1, \n",
    "                'transformer.h.0.mlp.c_fc.weight':p0, \n",
    "                'transformer.h.0.mlp.c_proj.weight':p0, \n",
    "                'transformer.ln_f.weight':p1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one epoch\n",
    "for _ in range(1000):\n",
    "    X, Y = get_batch()\n",
    "    t0 = time.time()\n",
    "    logits, loss = model(X, Y)\n",
    "\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for pn, p in model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                p -= lr* p.grad * torch.bernoulli(torch.ones_like(p)*(1-dropout_dict[pn]))\n",
    "    #optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    t1 = time.time()\n",
    "    #print(\"time: \", t1 - t0)\n",
    "    #print(\"%.2f\" % loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4387\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X, Y = get_batch(\"val\")\n",
    "    logits, loss = model(X, Y)\n",
    "    print(\"%.4f\" % loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
